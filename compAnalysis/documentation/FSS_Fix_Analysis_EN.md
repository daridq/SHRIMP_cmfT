# CFM FSS Fix Analysis

## ðŸš¨ Problem Discovery

During CFM training, we discovered abnormally high FSS values (0.99+), which is clearly abnormal. Normal precipitation prediction FSS values should be in the range of 0.1-0.5.

### Abnormal Log Examples

```
Epoch: 4/100 | 73.52s | Loss: 0.2686363416 | Val_loss: 0.2692165820 | Val_fss: 0.9910661306
Epoch: 5/100 | 74.34s | Loss: 0.2672936717 | Val_loss: 0.2894086932 | Val_fss: 0.9309849879
Epoch: 6/100 | 73.91s | Loss: 0.2663216000 | Val_loss: 0.2750107928 | Val_fss: 0.9789647348
```

## ðŸ” Root Cause Analysis

### Problem 1: Wrong Comparison Objects

**Incorrect CFM FSS Implementation**:

```python
# âŒ Wrong: comparing vector field vs vector field
target_vf = x1 - (1 - self.sigma_min) * x0  # vector field
pred_vf = self.nn_module(...)  # predicted vector field
fss = avg_fss(pred_vf/2+0.5, target_vf/2+0.5)
```

**Correct Diffusion FSS Implementation**:

```python
# âœ… Correct: comparing precipitation prediction vs actual precipitation
if self.target_type == "pred_x_0":
    gt_target = x  # original precipitation data
pred_target = self.nn_module(...)  # predicted precipitation data
fss = avg_fss(pred_target/2+0.5, gt_target/2+0.5)
```

### Problem 2: Data Range Mismatch

**Vector Field Numerical Characteristics**:

- Vector field values can be in very large ranges (e.g., [-10, 10] or larger)
- `/2+0.5` normalization assumes input is in `[-1, 1]` range
- When vector field values are large, normalization may turn everything into 0 or 1
- Causes numerical issues in FSS calculation

**Precipitation Data Numerical Characteristics**:

- Precipitation values are usually in reasonable ranges (e.g., [0, 1] or [0, 10])
- `/2+0.5` normalization is more suitable for this type of data
- FSS calculation is more meaningful

## ðŸ› ï¸ Fix Solution

### Core Idea

Change CFM's FSS calculation from "comparing vector fields" to "comparing precipitation predictions" to make it consistent with Diffusion.

### Fix Steps

1. **Recover precipitation prediction from vector field**:

   ```python
   # CFM vector field definition: target_vf = x1 - (1-Ïƒ_min)*x0
   # Therefore: x1 = target_vf + (1-Ïƒ_min)*x0
   pred_x1 = pred_vf + (1 - self.sigma_min) * x0
   gt_x1 = x  # actual precipitation data
   ```

2. **Compare precipitation data instead of vector fields**:
   ```python
   # Now comparing precipitation prediction vs actual precipitation
   fss_result = avg_fss(pred_x1/2+0.5, gt_x1/2+0.5)
   ```

### Complete Fix Code

```python
@torch.no_grad()
def fss(self, x: torch.Tensor, cond, lead_time, gf_sigmat=0):
    """
    Compute FSS in a way that's comparable to diffusion model
    Compare network prediction vs ground truth target (not final samples)

    For CFM, we need to compare the final prediction (x_0) vs ground truth,
    not the vector field predictions.
    """
    bsz, *_ = x.shape

    try:
        # Sample random time (similar to diffusion)
        t = torch.rand(bsz, device=x.device)  # t ~ U[0,1]
        lead_time = torch.full((bsz,), lead_time, device=x.device, dtype=torch.int64)

        # Sample noise
        x0 = torch.randn_like(x)
        if gf_sigmat > 0:
            x0 = torch.tensor(gaussian_filter(x0.cpu().numpy(), sigma=gf_sigmat), device=x.device)

        # Sample from conditional path
        x_t, target_vf = self.sample_conditional_path(t, x0, x)

        # Predict vector field
        t_discrete = (t * self.num_timesteps).long().clamp(0, self.num_timesteps - 1)
        pred_vf = self.nn_module(torch.cat((x_t, cond), dim=1), t_discrete, lead_time)

        # Convert vector field prediction to data prediction
        # target_vf = x_1 - (1-Ïƒ_min)*x_0, so x_1 = target_vf + (1-Ïƒ_min)*x_0

        # Ground truth x_1 (the actual data)
        gt_x1 = x

        # Predicted x_1 from vector field
        pred_x1 = pred_vf + (1 - self.sigma_min) * x0

        # Now compare predicted vs actual precipitation data (like diffusion)
        fss_result = avg_fss(pred_x1/2+0.5, gt_x1/2+0.5)

        # Validate FSS result
        if np.isnan(fss_result) or np.isinf(fss_result):
            return torch.tensor(0.0, device=x.device)

        return torch.tensor(fss_result, device=x.device)

    except Exception as e:
        # If anything fails, return 0 instead of crashing
        return torch.tensor(0.0, device=x.device)
```

## ðŸ“Š Expected Fix Results

### Before Fix (Incorrect)

- FSS values: 0.99+ (abnormally high)
- Reason: Comparing vector fields, numerical range mismatch
- Problem: Cannot fairly compare with Diffusion models

### After Fix (Correct)

- FSS values: 0.1-0.5 (normal range)
- Reason: Comparing precipitation predictions, semantically correct
- Advantage: Comparable with Diffusion models

## ðŸ”¬ Technical Deep Analysis

### CFM vs Diffusion FSS Semantics

**Diffusion FSS Semantics**:

- Measures: Whether network can correctly predict target (precipitation/noise/v-parameter)
- Meaning: Single-step prediction accuracy
- Range: Reasonable FSS values

**CFM FSS Semantics (Before Fix)**:

- Measures: Whether network can correctly predict vector field
- Problem: Vector field is not the final target, and numerical range is inappropriate
- Result: Abnormal FSS values

**CFM FSS Semantics (After Fix)**:

- Measures: Whether network can correctly predict precipitation data
- Meaning: Same single-step prediction accuracy as Diffusion
- Range: Reasonable FSS values

### Mathematical Derivation

**CFM Optimal Transport Path**:

```
x_t = (1-(1-Ïƒ_min)*t) * x_0 + t * x_1
```

**Vector Field Definition**:

```
u_t = dx/dt = x_1 - (1-Ïƒ_min) * x_0
```

**Recovering Data from Vector Field**:

```
x_1 = u_t + (1-Ïƒ_min) * x_0
```

This recovery formula is the key to the fix, converting vector field predictions to data predictions.

## ðŸ§ª Validation Methods

### 1. Numerical Range Check

```python
# Check numerical range of vector field vs data
print(f"Vector field range: [{pred_vf.min():.3f}, {pred_vf.max():.3f}]")
print(f"Data prediction range: [{pred_x1.min():.3f}, {pred_x1.max():.3f}]")
```

### 2. FSS Value Reasonableness Check

```python
# FSS should be in reasonable range [0, 1]
assert 0 <= fss_result <= 1, f"FSS out of range: {fss_result}"

# For precipitation prediction, FSS typically in [0.1, 0.5]
if fss_result > 0.8:
    print(f"Warning: FSS unusually high: {fss_result}")
```

### 3. Comparison with Diffusion

```python
# Run same data through both models
diffusion_fss = diffusion_model.fss(x, cond, lead_time)
cfm_fss = cfm_model.fss(x, cond, lead_time)

print(f"Diffusion FSS: {diffusion_fss:.4f}")
print(f"CFM FSS: {cfm_fss:.4f}")
print(f"Difference: {abs(diffusion_fss - cfm_fss):.4f}")
```

## ðŸ“ˆ Expected Improvements

After the fix, you should see:

1. **Stable FSS Values**: No more `nan` values
2. **Comparable FSS**: Can directly compare with diffusion model FSS
3. **Meaningful FSS**: Reflects network performance on training targets
4. **Training Monitoring**: Can observe FSS improvement trends during training

## ðŸ”¬ Theoretical Foundation

### Why This Fix is Correct

1. **Semantic Consistency**: Both CFM and Diffusion now measure the same thing - network's ability to predict meaningful targets
2. **Numerical Stability**: Comparing data predictions instead of vector fields ensures appropriate numerical ranges
3. **Fair Comparison**: Enables direct performance comparison between CFM and Diffusion models
4. **Training Signal**: Provides meaningful feedback for model optimization

### Mathematical Justification

The fix is mathematically sound because:

- CFM trains to predict vector field: `u_t = x_1 - (1-Ïƒ_min)*x_0`
- We can recover the data prediction: `x_1 = u_t + (1-Ïƒ_min)*x_0`
- This recovered `x_1` is what we should compare against ground truth
- This makes CFM FSS semantically equivalent to Diffusion FSS

This fix ensures that CFM and Diffusion models are evaluated on the same semantic basis, enabling fair performance comparisons and meaningful training monitoring.
